---
title: "BBVA"
author: "Blanca Alonso"
date: "19 Feb 2015"
output: html_document
---

```{r}
require(maptools)
library(rgdal)
library(ggplot2)
library(ggmap)
library(fields)
library(sp)
files = list.files("BBVA", full.names=T); files 
# [1] "BBVA/age_distribution000"         "BBVA/basic_stats000"             
# [3] "BBVA/customer_zipcodes000"        "BBVA/demographic_distribution000"
# [5] "BBVA/expenditure-time_curve000"   "BBVA/gender_distribution000"     
# [7] "BBVA/payment_distribution000" 

# Loading required tables created in 'Loading Telefonica & BBVA data.Rmd':
td_B=read.table("td_B.txt", sep="\t"); str(td_B); head(td_B) # BBVA tiles geo info 1
t_=read.table("t_.txt", sep="\t"); str(t_); head(t_) # BBVA tiles geo info 2
d_p_=read.table("d_p_.txt", sep="\t"); str(d_p_); head(d_p_) # BBVA polygons data
d_map=read.table("d_map.txt", sep="\t"); str(d_map); head(d_map) # Telefonica polygons data
zc_tid=read.table("zc_tid.txt", sep="\t"); str(zc_tid); head(zc_tid) # relational table  zipcode - tiles 
dti=read.table("dti.txt", sep="\t"); str(dti); head(dti) # traffic index per tile

WGS84=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
```

RShiny: Grid of tiles: reformating polygons data for mapping
```{r}
lat=c(); lon=c(); tid=c()
for (i in 1:nrow(t_)){
  lat=append(lat, c(t_$lat[i], t_$lat0[i], t_$lat1[i], t_$lat2[i], t_$lat[i], NA))
  lon=append(lon, c(t_$lon[i], t_$lon0[i], t_$lon1[i], t_$lon2[i], t_$lon[i], NA))
  tid=append(tid, c(rep(i, 6)))
}
pol=round(data.frame(lat, lon, tid), 3); head(pol)
write.table(pol, "shinyApp/pol.txt", sep="\t")
```

# Transaction data overview: basic stats data file

Basic stats and tile information extraction:
```{r}
files = list.files("BBVA", full.names=T); files 
t0=read.table(files[2], sep="\t", header=F, stringsAsFactors=F); str(t0); head(t0)
colnames(t0)=c("lat", "lon", "date", "sector", "nm", "nc", "nt", "avgt", "maxt", "mint", "stdt")
t0$date=strptime(t0$date, format="%Y-%m-%d")
t0$sector=as.factor(t0$sector); str(t0); head(t0)
```

Including tile ID:
```{r}
t0=merge(x=t0, y=td_B[, 1:3], by=c("lat","lon"), all.x=T); str(t0)
```

Calculating IQR-related thresholds : 
```{r}
# By tile:
a0=aggregate(.~ tid, data=t0[, c(5,6,7,8,12)], median); str(a0)
a1=aggregate(.~ tid + sector, data=t0[, c(4,5,6,7,8,12)], median); str(a1)

# Median and lower & upper IQR thresholds (upper/lower +/- 1.5*IQR) by sector
bs=NULL
bs=aggregate(.~ sector, data=a1[,c(2,3,4,5,6)], FUN=median); head(bs, 100)
bs_=aggregate(.~ sector, data=a1[,c(2,3,4,5,6)], FUN=function(x) {quantile(x)[4]+1.5*IQR(x)}); colnames(bs_)[2:5]=c('ut_nm', 'ut_nc', 'ut_nt', 'ut_avgt')
bs=merge(x=bs, y=bs_, by=('sector'), ALL.x=T)
bs__=aggregate(.~ sector, data=a1[,c(2,3,4,5,6)], FUN=function(x) {quantile(x)[2]-1.5*IQR(x)}); colnames(bs__)[2:5]=c('lt_nm', 'lt_nc', 'lt_nt', 'lt_avgt')
bs=merge(x=bs, y=bs__, by=('sector'), ALL.x=T); head(bs, 100)
```

Overview: "nt" > median*1.5 IQR & "nm" < median (by sector)
```{r}
op=data.frame(tid=c(), sector=c(), nm=c(), nc=c(), nt=c(), avgt=c()); r=c()
for (i in 1:dim(a1)[1]){
  if (a1$nt[i]>bs$ut_nt[bs$sector==a1$sector[i]] & a1$nm[i]<bs$nm[bs$sector==a1$sector[i]]){
    op=rbind(op, a1[i,])
    r=append(r, round(a1$nt[i]/bs$nt[bs$sector==a1$sector[i]], 2))
    } 
}; op$r=r; str(op)
```
  
Overview: "nm" < median and "avgt" > median 
```{r}
op2=data.frame(tid=c(), sector=c(), nm=c(), nc=c(), nt=c(), avgt=c()); r=c()
for (i in 1:dim(a1)[1]){
  if (a1$nm[i]<bs$nm[bs$sector==a1$sector[i]] & a1$avgt[i]>bs$ut_avgt[bs$sector==a1$sector[i]]){
    op2=rbind(op2, a1[i,])
    r=append(r, round(a1$nm[i]/bs$nm[bs$sector==a1$sector[i]], 2))
    }
}; 
op2$r=r
str(op2); op2[order(op2$tid),]
```


## Selecting opportunities: 1# By consumption patterns

# BBVA data: crossing time dynamics with demographics

Loading transaction data by demographics:
```{r}
files = list.files("BBVA", full.names=T); files 
t1=read.table(files[4], sep="\t", header=F, stringsAsFactors=F)
colnames(t1)=c("lat", "lon", "date", "sector","agei", "gen", "nm","nc","nt","avgt", "maxt", "mint", "stdt")
#t1$date=strptime(t1$date, format="%Y-%m-%d")
#sum(t1$agei=='unknown') # 1045 obs.
#sum(t1$gen=='unknown') # 1045 obs.
t1$sector=as.factor(t1$sector)
t1$agei=as.factor(t1$agei)
t1$gen=as.factor(t1$gen)
#t1$wd=as.factor(weekdays(t1$date))
str(t1); head(t1) # 2482 obs. 
head(t1[order(t1$date), ], 100)
#t1$wd=as.POSIXlt(t1$date)$wday
```

Including tile ID:
```{r}
t1=merge(x=t1, y=td_B[, 1:3], by=c("lat","lon"), all.x=T)
```

Loading Intra-week dynamics:
```{r}
files = list.files("BBVA", full.names=T); files 
t5=read.table(files[5], sep="\t", header=F, stringsAsFactors=F)
colnames(t5)=c("lat", "lon", "date", "wd_", "time", "nm","nc","nt","avgt", "maxt", "mint", "stdt")
t5$datetime=paste(t5$date, t5$time, sep=" ")
t5$date=strptime(t5$date, format="%Y-%m-%d")
t5$datetime=strptime(t5$datetime, format="%Y-%m-%d %H")
t5$wd=as.factor(t5$datetime$wday)
str(t5); head(t5)

ggplot(t5, aes(datetime, nt)) + geom_line()  + xlab("") + ylab("")
```

Including tile ID and categorical variables for transaction time range ('1': morning; '2': afternoon):
```{r}
t5=merge(x=t5, y=td_B[, 1:3], by=c("lat","lon"), all.x=T)
t5$dp=rep(NA, dim(t5)[1]); t5[t5$time<=15,]$dp=1; t5[t5$time>15,]$dp=2; t5$dp=as.factor(t5$dp); head(t5) # time range
```

Data preparation and clustering
```{r}
t1_c=t1[t1$age!='unknown', ]; sum(t1_c$gender=='unknown')
t5$date=strftime(t5$date, format="%Y-%m-%d")
t5_=aggregate(cbind(nm, nc, nt, avgt, maxt, mint)~tid+wd+dp+date, data=t5, mean)
colnames(t5_)[5:10]=c('nm_t', 'nc_t', 'nt_t', 'avgt_t', 'maxt_t', 'mint_t') # t: total; vs. by demographics in t1_c
td_dd=merge(x=t1_c, y=t5_, by=c('tid', 'date'), all.x=T); head(td_dd) # time dynamics_demographic data

#a3=aggregate(nt ~ tid + gen + agei + sector + wd + dp, data=td_dd, mean); head(a3)
a4=aggregate(cbind(avgt, nt) ~ tid + gen + agei + sector + wd + dp, data=td_dd, mean); head(a4)

p3=cast(td_dd, tid ~ gen + agei + sector + wd + dp, value='avgt', mean)
p3[is.na(p3)]=0; dim(p3)
p4=cast(td_dd, tid + sector ~ gen + agei + wd + dp, value='avgt', mean); 
p4[is.na(p4)]=0; dim(p4)

# Clustering
d=dist(p3)
fit=hclust(d, method="ward.D")
plot(fit)
rect.hclust(fit, k=6, border="red")

groups=cutree(fit, k=6)
plotcluster(p3, groups)
p3$clus=groups

d=dist(p4)
fit=hclust(d, method="ward.D")
plot(fit, label=F)
rect.hclust(fit, k=6, border="red")

groups=cutree(fit, k=6)
plotcluster(p4, groups)

df=p4; df$clus=groups
ggplot(df, aes(x = tid, y = sector)) + geom_point(aes(color=factor(clus)), size=2.5)

#---------- K-means approach
wss=(nrow(p4)-1)*sum(apply(p4, 2, var))
for (i in 2:15) wss[i] <- sum(kmeans(p4, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")

# K-Means Cluster Analysis
fit=kmeans(p4, 6); length(fit$cluster)
groups=data.frame(cluster=fit$cluster); groups$cluster
i=data.frame(tid=rownames(groups));
library(stringr)
s=str_split_fixed(i$tid, "_", 2); split1=data.frame(tid= s[, 1]); split2=data.frame(tid= s[, 2])
clus=data.frame(tid=split1, sector=split2, clus=groups$cluster); names(clus)=c('tid', 'sector', 'clus'); clus

agg=aggregate(cbind(avgt, nt) ~ tid + sector, data=td_dd, mean); head(agg)
t=merge(x=agg, y=clus, by=c('tid', 'sector'), all.x=T); t

ggplot(t, aes(x = sector, y = nt)) + geom_point(aes(color=factor(clus)), size=3)
#----------

# Relational table tid <-> cluster
tid_clus_avgt=df[, c('tid', 'sector', 'clus')]; tid_clus_avgt
```

Visualizing clusters:
```{r}
a0=aggregate(cbind(nt, avgt, nt_t, avgt_t, nc_t) ~ tid + sector, data=td_dd, mean); str(a0); head(a0)
a1=aggregate(cbind(nt, avgt) ~ tid + sector, data=td_dd, mean); str(a1); head(a1)

plot0=merge(a0, tid_clus_avgt, by=c('tid', 'sector'), all.x=T); plot0
plot1=merge(a1, tid_clus_avgt, by=c('tid', 'sector'), all.x=T); plot1

ggplot(plot0, aes(x = avgt, y = sector)) + geom_point(aes(color=factor(clus)), size=4)
```

```{r}
# Clustering of variables: visualization of the relation between categorical variables
library(ClustOfVar)
a4=aggregate(cbind(avgt, nt) ~ tid + gen + agei + sector + wd + dp, data=td_dd, mean); head(a4)
cv=hclustvar(a4[, 7], a4[, -c(1, 7, 8)])
plot(cv)
```

Selecting opportunities: same consumption patterns and avg transaction value + low nt/traffic index
```{r}
# Using clustering over 'avgt' (p4):
td_dd_cl=merge(x=td_dd[1:16], y=tid_clus_avgt, by=c('tid', 'sector'), all.x=T) # check: td_dd: 2873 - td_dd_cl: 2873 
td_dd_cl=merge(x=td_dd_cl, y=dti, by=('tid'), all.x=T)  # Including traffic index data
td_dd_cl$nt_n=td_dd_cl$nt / td_dd_cl$ti # Normalizing by traffic index
td_dd_cl$wd=as.factor(td_dd_cl$wd)
str(td_dd_cl); head(td_dd_cl) # 2873 obs. of  25 variables

dem_avg_bt=aggregate(.~ clus + tid + sector + agei + gen, data=td_dd_cl[, -c(3, 4, 5)], mean) # by tile
str(dem_avg_bt); head(dem_avg_bt) # 284 obs. of  16 variables:
head(dem_avg_bt[dem_avg_bt$tid==42,],)

dem_avg_bc=aggregate(.~ clus + sector + agei + gen, data=dem_avg_bt[, c(1, 3, 4, 5, 6, 7, 8, 9, 15, 16) ], mean); str(dem_avg_bc) # by cluster
colnames(dem_avg_bc)[c(5, 6, 7, 8, 9, 10)]=c('nm_c', 'nc_c', 'nt_c', 'avgt_c', 'ti_c', 'nt_n_c'); head(dem_avg_bc) # 157 obs.

vis_clus=aggregate(.~clus + sector + agei + gen, data=dem_avg_bt, mean); 
vis_clus=vis_clus[order(vis_clus$clus), ]; vis_clus

## Opportunities by nt: comparing each tile nt_t with average of cluster
opp_nt=merge(x=dem_avg_bt, y=dem_avg_bc, by=c('clus', 'sector', 'agei', 'gen'), all.x=T); 
str(opp_nt); head(opp_nt)  # 1469 obs. 
head(opp_nt[order(opp_nt$tid), ], 20)
head(opp_nt[opp_nt$tid==42,], 20)

## Opp 1: nt_n very low (low nt, but high ti)
opp_nt$nt_n_i=0
opp_nt$opp1=0
for (i in 1:dim(opp_nt)[1]){
  if (opp_nt$nt_n[i] < opp_nt$nt_n_c[i]) {
    opp_nt$nt_n_i[i]=(opp_nt$nt_n[i]/opp_nt$nt_n_c[i]) - 1
    if (opp_nt$nt_n_i[i] < -0.95) {opp_nt$opp1[i]=1}
    else if (opp_nt$nt_n_i[i] < -0.90) {opp_nt$opp1[i]=2}
    else if (opp_nt$nt_n_i[i] < -0.85) {opp_nt$opp1[i]=3}
    }
}; 
opp1_1=opp_nt[opp_nt$opp1==1,]; str(opp1_1) # 0 obs.
opp1_2=opp_nt[opp_nt$opp1==2,]; str(opp1_2) # 7 obs.
opp1_3=opp_nt[opp_nt$opp1==3,]; str(opp1_3) # 16 obs.
opp1=rbind(opp1_1, opp1_2, opp1_3); opp1

# Plotting results - example:
o=opp1[order(opp1$tid), ]; o
fashion=o[o$tid==45 & o$sector=='es_fashion', ]; fashion

write.csv(dti, "traffic_index.csv", sep="\t")
write.csv(fashion, "fashion_45.csv", sep="\t")
write.csv(tid_clus_avgt, "clusters.csv", sep="\t")
```

RShiny: Opp_1: reformating polygons data for mapping
```{r}
o1=NULL; o1=merge(opp1[order(opp1$tid), ], t_, by=('tid'), all.x=T); str(o1)
o1=o1[, c(1, 24:32)]; str(o1)

# Polygons
lat=c(); lon=c(); tid=c()
for (i in 1:nrow(o1)){
  lat=append(lat, c(o1$lat[i], o1$lat0[i], o1$lat1[i], o1$lat2[i], o1$lat[i], NA))
  lon=append(lon, c(o1$lon[i], o1$lon0[i], o1$lon1[i], o1$lon2[i], o1$lon[i], NA))
  tid=append(tid, c(rep(i, 6)))
}
op_1=round(data.frame(lat, lon, tid), 3); head(op_1)
write.table(op_1, "shinyApp/opp_1.txt", sep="\t")
```


Opp 2: high nt and high tf (scope for more businesses) (not included in the app)
```{r}
opp_nt=merge(x=dem_avg_bt, y=dem_avg_bc, by=c('clus', 'sector', 'agei', 'gen'), all.x=T); 
str(opp_nt); head(opp_nt)  # 1469 obs. 
head(opp_nt[order(opp_nt$nt, opp_nt$ti),])

opp_nt$nt_i=0
opp_nt$ti_i=0
opp_nt$opp2=0
for (i in 1:dim(opp_nt)[1]){
  if (opp_nt$nt[i] > opp_nt$nt_c[i] & opp_nt$ti[i] > opp_nt$ti_c[i]) {
    opp_nt$nt_i[i]=(opp_nt$nt[i]/opp_nt$nt_c[i]) - 1
    opp_nt$ti_i[i]=(opp_nt$ti[i]/opp_nt$ti_c[i]) - 1
    if (opp_nt$nt_i[i] > 1.5 & opp_nt$ti_i[i] > 1.5) {opp_nt$opp2[i]=1}
    else if (opp_nt$nt_i[i] > 1.0 & opp_nt$ti_i[i] > 1.0) {opp_nt$opp2[i]=2}
    }
}; 
opp2_1=opp_nt[opp_nt$opp2==1, ]; str(opp2_1) # 2 obs.
opp2_2=opp_nt[opp_nt$opp2==2, ]; str(opp2_2) # 

opp2=rbind(opp2_1, opp2_2)

max(opp_nt$nt_i); max(opp_nt$ti_i)
opp_nt[opp_nt$nt_i > 0.5, ]$ti_i
opp_nt[opp_nt$ti_i > 2.5, ]$nt_i
```


## Selecting opportunities: 2# By commuting distance
# Loading BBVA data: by customer zipcode: (top zc clients transaction data)

```{r}
files = list.files("BBVA", full.names=T); files 
t3=read.table(files[3], sep="\t", header=F, stringsAsFactors=F)
colnames(t3)=c("lat", "lon", "date", "sector","zc", "nm","nc","nt","avgt", "maxt", "mint", "stdt")
t3$date=strptime(t3$date, format="%Y-%m-%d")
t3$sector=as.factor(t3$sector)
t3$zc=as.factor(t3$zc)
str(t3); head(t3)
```

Including tile ID:
```{r}
t3=merge(x=t3, y=td_B[, 1:3], by=c("lat","lon"), all.x=T)
```

Merging basic stats (t0) and zc (t3) by tid, sector and date
```{r}
t3_=t3[, c(3, 4, 5, 8, 13)]
zd=merge(x=t0, y=t3_, by=c('date', 'sector', 'tid'), all.x=T); names(zd)[c(8, 14)]=c('nt', 'nt_zc')
zd$ntzc_p=(zd$nt_zc)/(zd$nt)
# Clean of unknowns & NA:
zd_c=zd[!is.na(zd$zc) & zd$zc!='unknown',]
# Clean of 'foreign' zc:
# zipcode data clean and local/foreign
zd_c_l=zd_c[as.numeric(as.character(zd_c$zc))>=48000, ] # 1277
zd_c_f=zd_c[as.numeric(as.character(zd_c$zc))<=48000, ] # 7
```

# Crossing zipcode transaction data with time dynamics

Intra-week dynamics:
```{r}
files = list.files("BBVA", full.names=T); files 
t5=read.table(files[5], sep="\t", header=F, stringsAsFactors=F)
colnames(t5)=c("lat", "lon", "date", "wd_", "time", "nm","nc","nt","avgt", "maxt", "mint", "stdt")
t5$datetime=paste(t5$date, t5$time, sep=" ")
t5$date=strptime(t5$date, format="%Y-%m-%d")
t5$datetime=strptime(t5$datetime, format="%Y-%m-%d %H")
t5$wd=as.factor(t5$datetime$wday)
str(t5); head(t5)
```

Including tile ID and categorical variables for transaction time rabe ('1': morning; '2': afternoon):
```{r}
t5=merge(x=t5, y=td_B[, 1:3], by=c("lat","lon"), all.x=T)
t5$dp=rep(NA, dim(t5)[1]); t5[t5$time<=15,]$dp=1; t5[t5$time>15,]$dp=2; t5$dp=as.factor(t5$dp); head(t5)
```

Crossing time dynamics with zipcodes and clustering (nt, avgt)
```{r}
t5_=aggregate(cbind(nt, avgt)~tid+wd+dp, data=t5, mean)
td_zc=merge(x=zd_c_l, y=t5_, by=c('tid'), all.x=T); head(td_zc)
a1=aggregate(round(nt.y,1) ~ zc + tid + sector + wd + dp, data=td_zc, mean); head(a1)
a2=aggregate(round(avgt.y,1) ~ zc + tid + sector + wd + dp, data=td_zc, mean); head(a2)

p1=cast(a1, zc ~ tid + sector + wd + dp); p1[is.na(p1)]=0; str(p1); head(p1)
p2=cast(a2, zc ~ tid + sector + wd + dp); p2[is.na(p2)]=0; str(p2); head(p2)

# clustering over a1 (nt) and a2 (avgt)
d=dist(p1, method = "euclidean") 
fit=hclust(d, method="ward.D") 
plot(fit)
rect.hclust(fit, k=5, border="red")

groups=cutree(fit, k=5)
plotcluster(p1, groups)
df1=p1; p1$clus=groups

pca=prcomp(df1)
gg=data.frame(cluster=factor(p1$clus), x=pca$x[, 1], y=pca$x[, 2])
# calculate cluster centroid locations
centroids=aggregate(cbind(x, y) ~ cluster, data=gg, mean)
# merge centroid locations into ggplot dataframe
gg=merge(gg, centroids, by="cluster", suffixes=c("",".centroid"))
# calculate 95% confidence ellipses
library(ellipse)
conf.rgn  <- do.call(rbind,lapply(1:3,function(i)
  cbind(cluster=i,ellipse(cov(gg[gg$cluster==i,2:3]),centre=as.matrix(centroids[i,2:3])))))
conf.rgn  <- data.frame(conf.rgn)
conf.rgn$cluster <- factor(conf.rgn$cluster)

# plot cluster map
ggplot(gg, aes(x,y, color=cluster))+
  geom_point(size=3) +
  geom_point(data=centroids, size=4) +
  geom_segment(aes(x=x.centroid, y=y.centroid, xend=x, yend=y))+
  geom_path(data=conf.rgn)
```

Associationg tile id to zc's in zc tansaction data (zd_c_l), and calculating distance between cust. zc and transaction tile:
```{r}
bs=merge(x=zd_c_l, y=zc_tid, by="zc") # 798 obs.
bs$dist=c(NA)
for (i in 1:dim(bs)[1]){
  bs$dist[i]=rdist.earth(matrix(c(td_B[td_B$tid==bs$tid[i], ]$clon, td_B[td_B$tid==bs$tid[i], ]$clat), ncol=2), matrix(c(td_B[td_B$tid==bs$zc_tid[i], ]$clon, td_B[td_B$tid==bs$zc_tid[i], ]$clat), ncol=2), miles=FALSE, R=6371)
  }; str(bs); head(bs)
min(bs$dist)

qplot (bs$dist, geom="blank") + geom_histogram (colour=I("white"), aes(y=..density..)) + stat_function(fun=dnorm, aes(colour="Normal"), arg=list(mean=mean(bs$dist), sd=sd(bs$dist)))
```

Looking for opp.: large distance movements
```{r}
op0=bs[bs$dist>1.5 & bs$dist<3.5, ]; str(op0); head(op0) # 197
tid_op0_o=data.frame(tid=unique(op0$zc_tid)); tid_op0_o
tid_op0_d=data.frame(tid=unique(op0$tid)); tid_op0_d

op1=bs[bs$dist>3.5 & bs$dist<9, ]; str(op1); head(op1) # 165
tid_op1_o=data.frame(tid=unique(op1$tid)); tid_op1_o
tid_op1_d=data.frame(tid=unique(op1$zc_tid)); tid_op1_d

op2=bs[bs$dist>9, ]; str(op2); op2[order(op2$date), ] # 32
tid_op2_o=data.frame(tid=unique(op2$tid)); tid_op2_o
tid_op2_d=data.frame(tid=unique(op2$zc_tid)); tid_op2_d

m0=aggregate(cbind(nt, avgt) ~ tid + sector, data=op0, mean); m0
write.csv(m0, "mobility_0.csv", sep="\t")
```

RShiny: Opp_2 polygons: reformating polygons data for mapping
```{r}
o2=NULL; o2=merge(tid_op0_o, t_, by=('tid'), all.x=T); str(o2); o2
o3=NULL; o3=merge(tid_op0_d, t_, by=('tid'), all.x=T); str(o3); o3

# Polygons
lat=c(); lon=c(); tid=c()
for (i in 1:nrow(o2)){
  lat=append(lat, c(o2$lat[i], o2$lat0[i], o2$lat1[i], o2$lat2[i], o2$lat[i], NA))
  lon=append(lon, c(o2$lon[i], o2$lon0[i], o2$lon1[i], o2$lon2[i], o2$lon[i], NA))
  tid=append(tid, c(rep(i, 6)))
}
op_2_o=round(data.frame(lat, lon, tid), 3); head(op_2_o)

lat=c(); lon=c(); tid=c()
for (i in 1:nrow(o3)){
  lat=append(lat, c(o3$lat[i], o3$lat0[i], o3$lat1[i], o3$lat2[i], o3$lat[i], NA))
  lon=append(lon, c(o3$lon[i], o3$lon0[i], o3$lon1[i], o3$lon2[i], o3$lon[i], NA))
  tid=append(tid, c(rep(i, 6)))
}
op_2_d=round(data.frame(lat, lon, tid), 3); head(op_2_d)

write.table(op_2_o, "shinyApp/opp_2_o.txt", sep="\t")
write.table(op_2_d, "shinyApp/opp_2_d.txt", sep="\t")
```

Plotting
```{r}
# Taking cent. of coordinates: customice by changing 'tid' & 'tid_zc'
c_op=data.frame(tid=op0$tid, tid_zc=op0$zc_tid)

for (i in 1:dim(c_op)[1]){ 
  c_op$clat[i]=td_B$clat[td_B$tid==c_op$tid[i]]
  c_op$clon[i]=td_B$clon[td_B$tid==c_op$tid[i]]
  c_op$clat_zc[i]=td_B$clat[td_B$tid==c_op$tid_zc[i]]
  c_op$clon_zc[i]=td_B$clon[td_B$tid==c_op$tid_zc[i]]
  }; str(c_op); head(c_op)

qmap(c(lon=mean(rbind(c_op$clon, c_op$clon_zc)), lat=mean(rbind(c_op$clat, c_op$clat_zc))), zoom = 12) + geom_point(data=c_op, aes(x=clon_zc, y=clat_zc), colour='blue', size=3) + geom_point(data=c_op, aes(x=clon, y=clat), colour='red', size=3)
```

